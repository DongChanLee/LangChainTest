{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnableLambda Embedding 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question. \\\n",
    "The user is from Korean. Answer the question in Korean.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "\n",
    "def prompt_router(input):\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A black hole is a region in space where gravity is so strong that nothing, not even light, can escape its pull. Black holes are formed when massive stars collapse under their own gravity. They have a boundary called the event horizon, beyond which nothing can escape. Inside the event horizon, the gravitational pull is so strong that it creates a singularity, a point of infinite density. Black holes can come in different sizes, from stellar-mass black holes to supermassive black holes found at the centers of galaxies.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What's a black hole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MATH\n",
      "적분이란 무엇인가요?\n",
      "\n",
      "적분은 미적분학에서 중요한 개념 중 하나로, 함수의 면적을 구하는 것을 의미합니다. 즉, 함수의 그래프와 x축이 이루는 영역의 면적을 계산하는 것입니다. 적분은 함수의 도함수인 미분과 반대되는 개념으로, 미분이 함수의 기울기를 나타내는 것과 달리 적분은 면적을 구하는 것을 나타냅니다. 적분은 수학적 모델링, 물리학, 공학 등 다양한 분야에서 사용되는 중요한 도구입니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What's a integral\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding 유사도 수치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도: 0.7442] You are a very smart physics professor. You are great at answering questions about physics in a concise and easy to understand manner. When you don't know the answer to a question you admit that you don't know. \t <=====> \t What's a black hole\n",
      "[유사도: 0.7108] You are a very smart physics professor. You are great at answering questions about physics in a concise and easy to understand manner. When you don't know the answer to a question you admit that you don't know. \t <=====> \t What's a integral\n",
      "[유사도: 0.7154] You are a very smart physics professor. You are great at answering questions about physics in a concise and easy to understand manner. When you don't know the answer to a question you admit that you don't know. \t <=====> \t Who's a Lionel Messi\n",
      "[유사도: 0.7702] What's a black hole \t <=====> \t What's a integral\n",
      "[유사도: 0.7495] What's a black hole \t <=====> \t Who's a Lionel Messi\n",
      "[유사도: 0.7307] What's a integral \t <=====> \t Who's a Lionel Messi\n"
     ]
    }
   ],
   "source": [
    "physics_template = \"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\"\n",
    "\n",
    "\n",
    "question1 = \"What's a black hole\"\n",
    "question2 = \"What's a integral\"\n",
    "question3 = \"Who's a Lionel Messi\"\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "sentences = [physics_template, question1, question2, question3]\n",
    "prompt_embeddings = embeddings.embed_documents(sentences)\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]\n",
    "\n",
    "\n",
    "for i, sentence in enumerate(prompt_embeddings):\n",
    "    for j, other_sentence in enumerate(prompt_embeddings):\n",
    "        if i < j:\n",
    "            print(f\"[유사도: {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
